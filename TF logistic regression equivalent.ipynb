{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from clean_data import load_clean_data as lcd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "       [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
       "       [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
       "       [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
       "       [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
       "       [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(100).reshape(10, 10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(20, 30)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.constant(a)\n",
    "y = tf.constant(b)\n",
    "xy = tf.mul(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,   21,   44,   69,   96,  125,  156,  189,  224,  261],\n",
       "       [ 200,  231,  264,  299,  336,  375,  416,  459,  504,  551],\n",
       "       [ 400,  441,  484,  529,  576,  625,  676,  729,  784,  841],\n",
       "       [ 600,  651,  704,  759,  816,  875,  936,  999, 1064, 1131],\n",
       "       [ 800,  861,  924,  989, 1056, 1125, 1196, 1269, 1344, 1421],\n",
       "       [1000, 1071, 1144, 1219, 1296, 1375, 1456, 1539, 1624, 1711],\n",
       "       [1200, 1281, 1364, 1449, 1536, 1625, 1716, 1809, 1904, 2001],\n",
       "       [1400, 1491, 1584, 1679, 1776, 1875, 1976, 2079, 2184, 2291],\n",
       "       [1600, 1701, 1804, 1909, 2016, 2125, 2236, 2349, 2464, 2581],\n",
       "       [1800, 1911, 2024, 2139, 2256, 2375, 2496, 2619, 2744, 2871]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "churn = pd.read_csv('data/churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>avg_rating_by_driver</th>\n",
       "      <th>avg_rating_of_driver</th>\n",
       "      <th>avg_surge</th>\n",
       "      <th>city</th>\n",
       "      <th>last_trip_date</th>\n",
       "      <th>phone</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>surge_pct</th>\n",
       "      <th>trips_in_first_30_days</th>\n",
       "      <th>luxury_car_user</th>\n",
       "      <th>weekday_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.67</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.10</td>\n",
       "      <td>King's Landing</td>\n",
       "      <td>2014-06-17</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>2014-01-25</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>46.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Astapor</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>Android</td>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.77</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Astapor</td>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.36</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.14</td>\n",
       "      <td>King's Landing</td>\n",
       "      <td>2014-06-29</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.13</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.19</td>\n",
       "      <td>Winterfell</td>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>Android</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>11.8</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "      <td>82.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_dist  avg_rating_by_driver  avg_rating_of_driver  avg_surge  \\\n",
       "0      3.67                   5.0                   4.7       1.10   \n",
       "1      8.26                   5.0                   5.0       1.00   \n",
       "2      0.77                   5.0                   4.3       1.00   \n",
       "3      2.36                   4.9                   4.6       1.14   \n",
       "4      3.13                   4.9                   4.4       1.19   \n",
       "\n",
       "             city last_trip_date    phone signup_date  surge_pct  \\\n",
       "0  King's Landing     2014-06-17   iPhone  2014-01-25       15.4   \n",
       "1         Astapor     2014-05-05  Android  2014-01-29        0.0   \n",
       "2         Astapor     2014-01-07   iPhone  2014-01-06        0.0   \n",
       "3  King's Landing     2014-06-29   iPhone  2014-01-10       20.0   \n",
       "4      Winterfell     2014-03-15  Android  2014-01-27       11.8   \n",
       "\n",
       "   trips_in_first_30_days luxury_car_user  weekday_pct  \n",
       "0                       4            True         46.2  \n",
       "1                       0           False         50.0  \n",
       "2                       3           False        100.0  \n",
       "3                       9            True         80.0  \n",
       "4                      14           False         82.4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, X, y = lcd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.32820408e-02,   1.57197882e-01,   1.35770184e-01,\n",
       "          2.24401251e-01,  -4.80727403e-03,  -9.55086610e-02,\n",
       "         -8.34610987e-01,  -1.36584803e-04,  -3.71074749e-02,\n",
       "          5.48977928e-03,  -1.03534154e+00,  -1.62733126e+00,\n",
       "         -4.73287434e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61260535])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.47      0.55      4564\n",
      "          1       0.74      0.87      0.80      7936\n",
      "\n",
      "avg / total       0.71      0.72      0.71     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72184\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_acc = accuracy_score(y_test, y_pred)\n",
    "print(logistic_regression_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_.reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs = tf.constant(model.coef_.reshape(-1, 1), dtype=tf.float32) # important! dtype must match x (what it's multiplied by)\n",
    "intercept = tf.constant(model.intercept_, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 13]) # 13 features in input data\n",
    "y = tf.placeholder(tf.float32, [None, 1]) # either a churn (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.sigmoid(tf.matmul(x, coefs) + intercept) # sigmoid makes it logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = sess.run(pred, feed_dict={x: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7939.373"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_round = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9283.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_round.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72184\n",
      "0.72184\n"
     ]
    }
   ],
   "source": [
    "neural_net_acc = accuracy_score(y_test, y_pred_round)\n",
    "print(neural_net_acc)\n",
    "print(logistic_regression_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now let's define a cost function and fit it, to make sure the weights don't change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "#model.coef_.reshape(-1, 1)\n",
    "#tf.zeros([13, 1]\n",
    "#model.intercept_\n",
    "#tf.zeros([1])\n",
    "\n",
    "coefs = tf.Variable(model.coef_.reshape(-1, 1), dtype=tf.float32) # important! dtype must match x (what it's multiplied by)\n",
    "intercept = tf.Variable(model.intercept_, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 13]) # 13 features in input data\n",
    "y = tf.placeholder(tf.float32, [None, 1]) # either a churn (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.sigmoid(tf.matmul(x, coefs) + intercept) # sigmoid makes it logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(pred, y), reduction_indices=1))/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.ops.variables.Variable at 0x7fd8882fe438>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd888316630>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd8841fb7b8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd8882edfd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd884173978>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd8c4051a90>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd8840e1b38>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd884123ef0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd8752f0390>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd8752eb080>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd8750f6f28>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd875318780>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd8750fc080>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd884199400>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd87502e668>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd8750340f0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874d8fac8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874d79c18>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874f83a58>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874db21d0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874db2208>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874bf8048>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874bf8080>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874bfe198>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874bfea90>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd8746f6fd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd8746829b0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd87462b5f8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd87462ae80>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd87462a5f8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd8745cabe0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd87446ca58>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd87439dc18>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874362ba8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd87436dba8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874371da0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd87436dbe0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874201e80>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874201ef0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86dd50358>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86dd50390>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86dd5d908>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86dd48470>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86dcf3b00>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86dcf3ba8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86dc88518>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86dc88550>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86dd90630>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d3c4e80>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d3e1588>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d3e1128>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86db31cc0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86db2b9e8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86da33208>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86da78eb8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d946a58>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d9469b0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d885588>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d3f98d0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86db056d8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d89efd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d7b93c8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d7b94a8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d751dd8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d755f60>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d7550b8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d75e0b8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874a78940>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd874201400>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d3c4fd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd8742b2e80>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d367d30>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86cd23518>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d306d30>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d307eb8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d3070f0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d307ef0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d307fd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d330668>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86c5a79b0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d49ba20>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d048a58>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d043cf8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d043c18>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d043d30>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d043da0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d043be0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d062f60>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86d07bcc0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86ce1cef0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86ce1cfd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86ce1cf28>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86ce1cf60>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86ce28b00>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86ce1ceb8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86cd87c50>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd86cde6c50>]"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.32820415e-02],\n",
       "       [  1.57197878e-01],\n",
       "       [  1.35770187e-01],\n",
       "       [  2.24401250e-01],\n",
       "       [ -4.80727386e-03],\n",
       "       [ -9.55086574e-02],\n",
       "       [ -8.34610999e-01],\n",
       "       [ -1.36584800e-04],\n",
       "       [ -3.71074751e-02],\n",
       "       [  5.48977917e-03],\n",
       "       [ -1.03534150e+00],\n",
       "       [ -1.62733126e+00],\n",
       "       [ -4.73287433e-01]], dtype=float32)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.32820408e-02],\n",
       "       [  1.57197882e-01],\n",
       "       [  1.35770184e-01],\n",
       "       [  2.24401251e-01],\n",
       "       [ -4.80727403e-03],\n",
       "       [ -9.55086610e-02],\n",
       "       [ -8.34610987e-01],\n",
       "       [ -1.36584803e-04],\n",
       "       [ -3.71074749e-02],\n",
       "       [  5.48977928e-03],\n",
       "       [ -1.03534154e+00],\n",
       "       [ -1.62733126e+00],\n",
       "       [ -4.73287434e-01]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = sess.run(cost, feed_dict=({x: X_train, y: y_train.reshape(-1, 1)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.094842069"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0.094842069]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([optimizer, cost], feed_dict=({x: X_train, y: y_train.reshape(-1, 1)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0948405\n"
     ]
    }
   ],
   "source": [
    "cs = sess.run(cost, feed_dict=({x: X_train, y: y_train.reshape(-1, 1)}))\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    sess.run([optimizer, cost], feed_dict=({x: X_train, y: y_train.reshape(-1, 1)}))\n",
    "    # y needs to be a row vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value Variable_24\n\t [[Node: Variable_24/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable_24\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_24)]]\nCaused by op 'Variable_24/read', defined at:\n  File \"/home/nate/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/nate/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-277-df32b7670984>\", line 10, in <module>\n    biases_out = tf.Variable(tf.random_normal([n_out]))\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 211, in __init__\n    dtype=dtype)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 323, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1106, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nate/anaconda3/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    449\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    451\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_24\n\t [[Node: Variable_24/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable_24\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_24)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-284-df2ee8190417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_24\n\t [[Node: Variable_24/read = Identity[T=DT_FLOAT, _class=[\"loc:@Variable_24\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_24)]]\nCaused by op 'Variable_24/read', defined at:\n  File \"/home/nate/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/nate/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-277-df32b7670984>\", line 10, in <module>\n    biases_out = tf.Variable(tf.random_normal([n_out]))\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 211, in __init__\n    dtype=dtype)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 323, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1106, in identity\n    result = _op_def_lib.apply_op(\"Identity\", input=input, name=name)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2317, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/nate/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1239, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "y_pred = sess.run(pred, feed_dict=({x: X_test}))\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_round))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! We can actually get a slightly better score than with just plain logistic regression.  Make sure to keep the learning rate low since we're close to the answer.  When I tried with the learning rate as 0.01 it actually made the fit worse.  Now let's make a NN with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_sess = tf.Session()\n",
    "\n",
    "coefs = tf.Variable(model.coef_.reshape(-1, 1), dtype=tf.float32) # important! dtype must match x (what it's multiplied by)\n",
    "intercept = tf.Variable(model.intercept_, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 13]) # 13 features in input data\n",
    "y = tf.placeholder(tf.float32, [None, 1]) # either a churn (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_input = 13\n",
    "n_hidden_1 = 13*13\n",
    "n_out = 1\n",
    "weights_1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "biases_1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "layer_1 = tf.add(tf.matmul(x, weights_1), biases_1)\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "weights_out = tf.Variable(tf.random_normal([n_hidden_1, n_out]))\n",
    "biases_out = tf.Variable(tf.random_normal([n_out]))\n",
    "out_layer = tf.matmul(layer_1, weights_out) + biases_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.sigmoid(out_layer) # sigmoid makes it logistic\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(pred, y), reduction_indices=1))/2.\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "deep_sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    deep_sess.run([optimizer, cost], feed_dict=({x: X_train, y: y_train.reshape(-1, 1)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49504\n"
     ]
    }
   ],
   "source": [
    "y_pred = deep_sess.run(pred, feed_dict=({x: X_test}))\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_round))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to max out at 49.5% accuracy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Started with learning rate at 10, then decreased to 1, 0.1, 0.01.  Big jump from mid-30s accuracy to 49% all of a sudden with learning rate=10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try some different number of hidden nodes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_sess2 = tf.Session()\n",
    "\n",
    "coefs = tf.Variable(model.coef_.reshape(-1, 1), dtype=tf.float32) # important! dtype must match x (what it's multiplied by)\n",
    "intercept = tf.Variable(model.intercept_, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 13]) # 13 features in input data\n",
    "y = tf.placeholder(tf.float32, [None, 1]) # either a churn (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 13\n",
    "n_hidden_1 = 13\n",
    "n_out = 1\n",
    "weights_1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "biases_1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "layer_1 = tf.add(tf.matmul(x, weights_1), biases_1)\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "weights_out = tf.Variable(tf.random_normal([n_hidden_1, n_out]))\n",
    "biases_out = tf.Variable(tf.random_normal([n_out]))\n",
    "out_layer = tf.matmul(layer_1, weights_out) + biases_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.sigmoid(out_layer) # sigmoid makes it logistic\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(pred, y), reduction_indices=1))/2.\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "deep_sess2.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    deep_sess2.run([optimizer, cost], feed_dict=({x: X_train, y: y_train.reshape(-1, 1)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63488\n"
     ]
    }
   ],
   "source": [
    "y_pred = deep_sess2.run(pred, feed_dict=({x: X_test}))\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_round))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to max out around 63.5% accuracy after 100 iteration with learning rate = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_sess3 = tf.Session()\n",
    "\n",
    "coefs = tf.Variable(model.coef_.reshape(-1, 1), dtype=tf.float32) # important! dtype must match x (what it's multiplied by)\n",
    "intercept = tf.Variable(model.intercept_, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 13]) # 13 features in input data\n",
    "y = tf.placeholder(tf.float32, [None, 1]) # either a churn (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 13\n",
    "n_hidden_1 = 6\n",
    "n_out = 1\n",
    "weights_1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "biases_1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "layer_1 = tf.add(tf.matmul(x, weights_1), biases_1)\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "weights_out = tf.Variable(tf.random_normal([n_hidden_1, n_out]))\n",
    "biases_out = tf.Variable(tf.random_normal([n_out]))\n",
    "out_layer = tf.matmul(layer_1, weights_out) + biases_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.sigmoid(out_layer) # sigmoid makes it logistic\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(pred, y), reduction_indices=1))/2.\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "deep_sess3.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    deep_sess3.run([optimizer, cost], feed_dict=({x: X_train, y: y_train.reshape(-1, 1)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63472\n"
     ]
    }
   ],
   "source": [
    "y_pred = deep_sess3.run(pred, feed_dict=({x: X_test}))\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_round))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like accuracy went down slightly.  Maybe if we try something between 13 and 13*13 for our number of nodes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_sess4 = tf.Session()\n",
    "\n",
    "coefs = tf.Variable(model.coef_.reshape(-1, 1), dtype=tf.float32) # important! dtype must match x (what it's multiplied by)\n",
    "intercept = tf.Variable(model.intercept_, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 13]) # 13 features in input data\n",
    "y = tf.placeholder(tf.float32, [None, 1]) # either a churn (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 13\n",
    "n_hidden_1 = 13*3\n",
    "n_out = 1\n",
    "weights_1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "biases_1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "layer_1 = tf.add(tf.matmul(x, weights_1), biases_1)\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "weights_out = tf.Variable(tf.random_normal([n_hidden_1, n_out]))\n",
    "biases_out = tf.Variable(tf.random_normal([n_out]))\n",
    "out_layer = tf.matmul(layer_1, weights_out) + biases_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.sigmoid(out_layer) # sigmoid makes it logistic\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(pred, y), reduction_indices=1))/2.\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "deep_sess4.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    deep_sess4.run([optimizer, cost], feed_dict=({x: X_train, y: y_train.reshape(-1, 1)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47776\n"
     ]
    }
   ],
   "source": [
    "y_pred = deep_sess4.run(pred, feed_dict=({x: X_test}))\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_round))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like this achitecture isn't going to work, it maxs out at 47.776% acc. Let's try again, but this time with the logistic part first (scaling each component, essentially), then the deep net after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_sess5 = tf.Session()\n",
    "\n",
    "coefs = tf.Variable(model.coef_.reshape(-1, 1), dtype=tf.float32) # important! dtype must match x (what it's multiplied by)\n",
    "intercept = tf.Variable(model.intercept_, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 13]) # 13 features in input data\n",
    "y = tf.placeholder(tf.float32, [None, 1]) # either a churn (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_input = 13\n",
    "n_hidden_1 = 13*2\n",
    "n_out = 1\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "weights_1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "biases_1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "layer_1 = tf.add(tf.matmul(x, weights_1), biases_1)\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "\n",
    "weights_out = tf.Variable(tf.random_normal([n_hidden_1, n_out]))\n",
    "biases_out = tf.Variable(tf.random_normal([n_out]))\n",
    "out_layer = tf.matmul(layer_1, weights_out) + biases_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.sigmoid(out_layer) # sigmoid makes it logistic\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(pred, y), reduction_indices=1))/2.\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "deep_sess5.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_prob = 0.5\n",
    "for i in range(100):\n",
    "    deep_sess5.run([optimizer, cost], feed_dict=({x: X_train, y: y_train.reshape(-1, 1)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6276\n"
     ]
    }
   ],
   "source": [
    "keep_prob = 1\n",
    "y_pred = deep_sess5.run(pred, feed_dict=({x: X_test}))\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_round))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe dropout helps?  Let's compare with a model we tried without dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_sess6 = tf.Session()\n",
    "\n",
    "coefs = tf.Variable(model.coef_.reshape(-1, 1), dtype=tf.float32) # important! dtype must match x (what it's multiplied by)\n",
    "intercept = tf.Variable(model.intercept_, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 13]) # 13 features in input data\n",
    "y = tf.placeholder(tf.float32, [None, 1]) # either a churn (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 13\n",
    "n_hidden_1 = 6\n",
    "n_out = 1\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "weights_1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "biases_1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "layer_1 = tf.add(tf.matmul(x, weights_1), biases_1)\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "\n",
    "weights_out = tf.Variable(tf.random_normal([n_hidden_1, n_out]))\n",
    "biases_out = tf.Variable(tf.random_normal([n_out]))\n",
    "out_layer = tf.matmul(layer_1, weights_out) + biases_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.sigmoid(out_layer) # sigmoid makes it logistic\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(pred, y), reduction_indices=1))/2.\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 1\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "deep_sess6.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    deep_sess6.run([optimizer, cost], feed_dict=({x: X_train, y: y_train.reshape(-1, 1), keep_prob: 0.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6348\n"
     ]
    }
   ],
   "source": [
    "y_pred = deep_sess6.run(pred, feed_dict=({x: X_test, keep_prob: 1.0}))\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_round))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we got 63.472...not a huge improvement.\n",
    "\n",
    "Alright.  Need at least 2 hidden layers for full generality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_sess7 = tf.Session()\n",
    "\n",
    "coefs = tf.Variable(model.coef_.reshape(-1, 1), dtype=tf.float32) # important! dtype must match x (what it's multiplied by)\n",
    "intercept = tf.Variable(model.intercept_, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 13]) # 13 features in input data\n",
    "y = tf.placeholder(tf.float32, [None, 1]) # either a churn (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 13\n",
    "n_hidden_1 = 13*2\n",
    "n_hidden_2 = 13*2\n",
    "n_out = 1\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "weights_1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "biases_1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "layer_1 = tf.add(tf.matmul(x, weights_1), biases_1)\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "\n",
    "weights_2 = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]))\n",
    "biases_2 = tf.Variable(tf.random_normal([n_hidden_2]))\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weights_2), biases_2)\n",
    "layer_2 = tf.nn.relu(layer_2)\n",
    "layer_2 = tf.nn.dropout(layer_2, keep_prob)\n",
    "\n",
    "weights_out = tf.Variable(tf.random_normal([n_hidden_2, n_out]))\n",
    "biases_out = tf.Variable(tf.random_normal([n_out]))\n",
    "out_layer = tf.matmul(layer_2, weights_out) + biases_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.sigmoid(out_layer) # sigmoid makes it logistic\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(pred, y), reduction_indices=1))/2.\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 10\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "deep_sess7.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    deep_sess7.run([optimizer, cost], feed_dict=({x: X_train, y: y_train.reshape(-1, 1), keep_prob: 0.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63488\n"
     ]
    }
   ],
   "source": [
    "y_pred = deep_sess7.run(pred, feed_dict=({x: X_test, keep_prob: 1.0}))\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_round))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seemed to converge much faster, but not much better than a single layer.  Let's keep adding layers I guess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_sess8 = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 13]) # 13 features in input data\n",
    "y = tf.placeholder(tf.float32, [None, 1]) # either a churn (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 13\n",
    "n_hidden_1 = 13*2\n",
    "n_hidden_2 = 13*2\n",
    "n_hidden_3 = 13*2\n",
    "n_out = 1\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "weights_1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "biases_1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "layer_1 = tf.add(tf.matmul(x, weights_1), biases_1)\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "\n",
    "weights_2 = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]))\n",
    "biases_2 = tf.Variable(tf.random_normal([n_hidden_2]))\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weights_2), biases_2)\n",
    "layer_2 = tf.nn.relu(layer_2)\n",
    "layer_2 = tf.nn.dropout(layer_2, keep_prob)\n",
    "\n",
    "weights_3 = tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3]))\n",
    "biases_3 = tf.Variable(tf.random_normal([n_hidden_3]))\n",
    "layer_3 = tf.add(tf.matmul(layer_2, weights_3), biases_3)\n",
    "layer_3 = tf.nn.relu(layer_3)\n",
    "layer_3 = tf.nn.dropout(layer_3, keep_prob)\n",
    "\n",
    "weights_out = tf.Variable(tf.random_normal([n_hidden_3, n_out]))\n",
    "biases_out = tf.Variable(tf.random_normal([n_out]))\n",
    "out_layer = tf.matmul(layer_3, weights_out) + biases_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.sigmoid(out_layer) # sigmoid makes it logistic\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(pred, y), reduction_indices=1))/2.\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 1\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "deep_sess8.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    deep_sess8.run([optimizer, cost], feed_dict=({x: X_train, y: y_train.reshape(-1, 1), keep_prob: 0.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63488\n"
     ]
    }
   ],
   "source": [
    "y_pred = deep_sess8.run(pred, feed_dict=({x: X_test, keep_prob: 1.0}))\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.ops.variables.Variable at 0x7fd867f73f28>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd867f73f60>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd867f73f98>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd867f73fd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd867f39a58>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd867f226d8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd867f73ef0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fd867f399b0>]"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deep_sess8 = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 13]) # 13 features in input data\n",
    "y = tf.placeholder(tf.float32, [None, 1]) # either a churn (1) or not (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 13\n",
    "n_hidden_1 = 13*10\n",
    "n_hidden_2 = 13*5\n",
    "n_hidden_3 = 13\n",
    "n_out = 1\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "weights_1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
    "biases_1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
    "layer_1 = tf.add(tf.matmul(x, weights_1), biases_1)\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "\n",
    "weights_2 = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]))\n",
    "biases_2 = tf.Variable(tf.random_normal([n_hidden_2]))\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weights_2), biases_2)\n",
    "layer_2 = tf.nn.relu(layer_2)\n",
    "layer_2 = tf.nn.dropout(layer_2, keep_prob)\n",
    "\n",
    "weights_3 = tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3]))\n",
    "biases_3 = tf.Variable(tf.random_normal([n_hidden_3]))\n",
    "layer_3 = tf.add(tf.matmul(layer_2, weights_3), biases_3)\n",
    "layer_3 = tf.nn.relu(layer_3)\n",
    "layer_3 = tf.nn.dropout(layer_3, keep_prob)\n",
    "\n",
    "weights_out = tf.Variable(tf.random_normal([n_hidden_3, n_out]))\n",
    "biases_out = tf.Variable(tf.random_normal([n_out]))\n",
    "out_layer = tf.matmul(layer_3, weights_out) + biases_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.sigmoid(out_layer) # sigmoid makes it logistic\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(pred, y), reduction_indices=1))/2.\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 1\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "deep_sess8.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    deep_sess8.run([optimizer, cost], feed_dict=({x: X_train, y: y_train.reshape(-1, 1), keep_prob: 0.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = deep_sess8.run(pred, feed_dict=({x: X_test, keep_prob: 1.0}))\n",
    "\n",
    "y_pred_round = np.round(y_pred)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
